<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Open Lipstick Try-On</title>

  <!-- Transformers.js -->
  <script src="https://cdn.jsdelivr.net/npm/@xenova/transformers"></script>

  <style>
    html, body {
      margin: 0;
      height: 100%;
      overflow: hidden;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      background: #000;
      color: #fff;
      font-family: sans-serif;
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1); /* mirror for selfie view */
    }
    #controls {
      position: absolute;
      top: 10px;
      left: 10px;
      background: rgba(255,255,255,0.8);
      color: #000;
      padding: 8px 12px;
      border-radius: 10px;
      z-index: 3;
    }
  </style>
</head>
<body>
  <div id="controls">
    Color <input type="color" id="colorPicker" value="#d45a73" />
    Opacity <input type="range" id="opacityRange" min="0" max="1" step="0.05" value="0.6" />
  </div>

  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { pipeline } from "https://cdn.jsdelivr.net/npm/@xenova/transformers";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const colorPicker = document.getElementById("colorPicker");
    const opacityRange = document.getElementById("opacityRange");

    // Setup webcam
    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await new Promise((r) => (video.onloadedmetadata = r));
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    // Load face parsing model (jonathandinu/face-parsing)
    const segmenter = await pipeline("image-segmentation", "jonathandinu/face-parsing");

    function hexToRgb(hex) {
      const r = parseInt(hex.slice(1,3),16);
      const g = parseInt(hex.slice(3,5),16);
      const b = parseInt(hex.slice(5,7),16);
      return {r,g,b};
    }

    async function renderFrame() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);

      // Run segmentation every few frames (to avoid lag)
      const segmentation = await segmenter(video);

      // segmentation.segmentation contains class index per pixel
      const mask = segmentation.segmentation;
      const {r, g, b} = hexToRgb(colorPicker.value);
      const opacity = parseFloat(opacityRange.value);

      const { data } = frame;
      for (let i = 0; i < mask.length; i++) {
        const cls = mask[i];
        // Lip class IDs from jonathandinu model: 7 = upper_lip, 8 = lower_lip
        if (cls === 7 || cls === 8) {
          const j = i * 4;
          data[j]   = data[j]*(1-opacity) + r*opacity;
          data[j+1] = data[j+1]*(1-opacity) + g*opacity;
          data[j+2] = data[j+2]*(1-opacity) + b*opacity;
        }
      }

      ctx.putImageData(frame, 0, 0);
      requestAnimationFrame(renderFrame);
    }

    async function main() {
      await setupCamera();
      renderFrame();
    }

    main();
  </script>
</body>
</html>

